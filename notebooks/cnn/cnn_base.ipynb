{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN基本结构单元\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T05:40:58.010430Z",
     "start_time": "2025-09-02T05:40:55.382644Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn as nn",
   "id": "331d8d0f4e153b7d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "激活函数层: 引入非线性，使网络能够学习复杂模式\n",
    "- inplace: 是否原地操作（节省内存）\n",
    "（最常用的是 ReLU，还有其变体如 LeakyReLU、PReLU 等）\n",
    "\"\"\"\n",
    "nn.ReLU(inplace=False)\n",
    "nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "nn.Sigmoid()\n",
    "nn.Tanh()"
   ],
   "id": "7398ffdfd9f44c4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "线性变换层: 执行 y = x @ W.T + b\n",
    "- in_features: 输入特征数（每个样本的输入维度）\n",
    "- out_features: 输出特征数（每个样本的输出维度）\n",
    "- bias: 是否使用偏置项（True/False）\n",
    "- device: 权重和偏置所在的设备（如 'cpu' 或 'cuda'）\n",
    "- dtype: 参数的数据类型（如 torch.float32）\n",
    "\"\"\"\n",
    "nn.Linear(in_features=16, out_features=8, bias=True, device=None, dtype=None)"
   ],
   "id": "5d6ae2c93309106a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:15:23.080345Z",
     "start_time": "2025-09-03T04:15:23.075301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "卷积层: 执行二维卷积操作 y = conv2d(x, W) + b\n",
    "- in_channels: 输入通道数（如灰度图=1，RGB图=3）\n",
    "- out_channels: 输出通道数（即卷积核的数量）\n",
    "- kernel_size: 卷积核的尺寸（可以是整数或元组，如 3 或 (3, 3)）\n",
    "- stride: 卷积步长（可以是整数或元组，默认为 1）\n",
    "- padding: 输入的填充大小（可以是整数或元组，默认为 0）\n",
    "- dilation: 卷积核元素间的间隔（即空洞率，默认为 1）\n",
    "- groups: 分组卷积的组数（1 为普通卷积，>1 为分组卷积，如深度可分离卷积）\n",
    "- bias: 是否使用偏置项（True/False）\n",
    "- padding_mode: 填充模式（如 'zeros', 'reflect', 'replicate', 'circular'，默认为 'zeros'）\n",
    "- device: 权重和偏置所在的设备（如 'cpu' 或 'cuda'）\n",
    "- dtype: 参数的数据类型（如 torch.float32）\n",
    "\"\"\"\n",
    "nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0,\n",
    "          dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)"
   ],
   "id": "a4329a59503d0eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:15:23.123926Z",
     "start_time": "2025-09-03T04:15:23.109894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "最大池化层: 对输入的每个通道应用滑动窗口，取窗口内的最大值，常用于特征下采样\n",
    "- kernel_size: 池化窗口的大小（整数或元组，如 2 或 (2, 2)）\n",
    "- stride: 池化步长（整数或元组，默认等于 kernel_size）\n",
    "- padding: 填充大小（整数或元组，用于边缘填充）\n",
    "- dilation: 窗口元素间的间隔（空洞池化，默认为 1）\n",
    "- return_indices: 是否返回最大值的索引（用于上采样恢复位置，如 MaxUnpool2d）\n",
    "- ceil_mode: 输出尺寸是否向上取整（True/False，默认 False）\n",
    "\"\"\"\n",
    "nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "\n",
    "\"\"\"\n",
    "平均池化层: 对池化窗口内的值取平均，用于平滑特征图或降维\n",
    "- kernel_size: 池化窗口的大小\n",
    "- stride: 池化步长\n",
    "- padding: 填充大小\n",
    "- ceil_mode: 是否对输出尺寸向上取整\n",
    "- count_include_pad: 计算平均值时是否包含填充的零值（True/False）\n",
    "\"\"\"\n",
    "nn.AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "\n",
    "\"\"\"\n",
    "自适应平均池化层: 自动调整池化窗口大小，使输出尺寸固定为指定值（常用于全局池化）\n",
    "- output_size: 输出的空间尺寸（整数或元组，如 1 或 (1, 1)，输出通道数不变）\n",
    "\"\"\"\n",
    "nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "\"\"\"\n",
    "自适应最大池化层: 类似自适应平均池化，但使用最大值操作\n",
    "- output_size: 指定输出的空间尺寸\n",
    "\"\"\"\n",
    "nn.AdaptiveMaxPool2d(output_size=(7, 7))\n",
    "\n",
    "\"\"\"\n",
    "分数最大池化层: 使用预定义的分数图进行池化，池化位置非固定（较少使用）\n",
    "- kernel_size: 池化窗口大小\n",
    "- alpha: 分数图的缩放系数（决定池化区域分布）\n",
    "- outputs_size 或 outputs_ratio: 指定输出尺寸或比例\n",
    "- return_indices: 是否返回索引\n",
    "\"\"\"\n",
    "nn.FractionalMaxPool2d(kernel_size=2, output_size=(7, 7))\n",
    "\n",
    "\"\"\"\n",
    "Lp 池化层: 使用 Lp 范数进行池化（p 通常为 2，即 L2 池化）\n",
    "- kernel_size: 池化窗口大小\n",
    "- stride: 步长\n",
    "- norm_type: Lp 范数的 p 值（如 2.0 表示 L2 池化）\n",
    "\"\"\"\n",
    "nn.LPPool2d(norm_type=2.0, kernel_size=3, stride=3)"
   ],
   "id": "6baf7d42f20eb7bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "展平层: 将张量的指定维度展平为一维，常用于卷积层与全连接层之间\n",
    "- start_dim: 展平起始维度（默认为 1，即保留 batch 维度）\n",
    "- end_dim: 展平结束维度（默认为 -1，即最后一个维度）\n",
    "\"\"\"\n",
    "nn.Flatten(start_dim=1, end_dim=-1)"
   ],
   "id": "7d8014865a9ffe0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "BatchNorm2d 层: 对每个通道的特征图进行批归一化，稳定训练、加速收敛\n",
    "- num_features: 输入的通道数（如卷积输出通道数）\n",
    "- eps: 防止除零的小数值（默认 1e-5）\n",
    "- momentum: 动态更新统计量时的动量系数（用于移动平均，默认 0.1）\n",
    "- affine: 是否学习缩放（weight）和平移（bias）参数（True/False）\n",
    "- track_running_stats: 是否跟踪运行时的均值和方差（训练时更新，推理时使用累积值）\n",
    "\"\"\"\n",
    "nn.BatchNorm2d(num_features=64, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "\"\"\"\n",
    "BatchNorm1d 层: 用于全连接层或序列数据的批归一化\n",
    "- num_features: 输入特征的维度（即特征数）\n",
    "- eps, momentum, affine, track_running_stats: 含义同 BatchNorm2d\n",
    "\"\"\"\n",
    "nn.BatchNorm1d(num_features=128, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)"
   ],
   "id": "3a99dae5ea9f22fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Dropout 层: 在训练期间以指定概率随机将输入张量的元素置零，防止过拟合\n",
    "- p: 置零的概率（默认 0.5，即每个元素有 50% 概率被丢弃）\n",
    "- inplace: 是否进行原地操作（节省内存，True/False，默认 False）\n",
    "\"\"\"\n",
    "nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "\"\"\"\n",
    "Dropout2d 层: 对整个通道（特征图）进行丢弃，常用于卷积网络\n",
    "- p: 通道丢弃的概率\n",
    "- inplace: 是否原地操作\n",
    "（与 Dropout 不同，它丢弃的是整个 (H, W) 特征图，保留通道相关性）\n",
    "\"\"\"\n",
    "nn.Dropout2d(p=0.5, inplace=False)\n",
    "\n",
    "\"\"\"\n",
    "Dropout3d 层: 类似 Dropout2d，用于 3D 输入（如体积数据或视频），丢弃整个通道\n",
    "- p: 丢弃概率\n",
    "- inplace: 是否原地操作\n",
    "\"\"\"\n",
    "nn.Dropout3d(p=0.5, inplace=False)\n",
    "\n",
    "\"\"\"\n",
    "Alpha Dropout 层: 配合 SELU 激活函数使用的 Dropout，保持输出的均值和方差不变（自归一化）\n",
    "- p: 丢弃概率\n",
    "- inplace: 是否原地操作\n",
    "\"\"\"\n",
    "nn.AlphaDropout(p=0.5, inplace=False)"
   ],
   "id": "d03b2a4e9ae086a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "零填充层: 在输入的边界填充零值\n",
    "- padding: 填充大小（可为整数或元组，如 1 或 (1,1,1,1)）\n",
    "- inplace: 是否原地操作\n",
    "（常用于保持卷积后特征图尺寸不变，或控制信息边界效应）\n",
    "\"\"\"\n",
    "nn.ZeroPad2d(padding=1)\n",
    "\n",
    "\"\"\"\n",
    "恒等映射层: 直接返回输入，常用于构建残差连接中的短路分支\n",
    "（无参数，用于网络结构设计，如 ResNet 中的 skip connection）\n",
    "\"\"\"\n",
    "nn.Identity()\n",
    "\n",
    "\"\"\"\n",
    "上采样层 / 转置卷积层: 用于特征图放大（上采样），如分割、生成模型\n",
    "- scale_factor: 放大倍数（如 2 表示宽高各放大 2 倍）\n",
    "- mode: 插值方式（如 'nearest', 'bilinear', 'bicubic'）\n",
    "- align_corners: 插值时是否对齐角点（影响边缘精度）\n",
    "\"\"\"\n",
    "nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)\n",
    "\n",
    "\"\"\"\n",
    "转置卷积层 (反卷积): 可学习的上采样方式，用于解码器结构\n",
    "- in_channels, out_channels: 输入/输出通道数\n",
    "- kernel_size, stride, padding: 卷积参数（注意 stride 起上采样作用）\n",
    "- output_padding: 补偿输出尺寸歧义\n",
    "- bias: 是否使用偏置\n",
    "（常用于生成图像或语义分割）\n",
    "\"\"\"\n",
    "nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True)\n",
    "\n",
    "\"\"\"\n",
    "残差块占位层: 用于构建残差网络（ResNet）的基本模块\n",
    "（实际由 Conv + BN + ReLU 等组合而成，但 `nn` 提供了标准实现）\n",
    "\"\"\"\n",
    "# 示例：实际使用的是组合结构，但可通过 Sequential 构建\n",
    "# 或直接使用 torchvision.models.resnet 中的 BasicBlock / Bottleneck"
   ],
   "id": "ff2bdab644f1558f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
